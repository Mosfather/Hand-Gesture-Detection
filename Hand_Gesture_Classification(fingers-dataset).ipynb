{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "import os\n",
    "plaidml.keras.install_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'plaidml.keras.backend' from 'C:\\\\Users\\\\Bamouh Mohamed\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\Projectenv\\\\lib\\\\site-packages\\\\plaidml\\\\keras\\\\backend.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "from pynput.keyboard import Key, Controller\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTest = \"fingers/test/*\"\n",
    "NUMBER_OF_CLASSES = 6\n",
    "#indice_to_label = {0:\"0L\", 1:\"1L\", 2:\"2L\", 3:\"3L\", 4:\"4L\", 5:\"5L\", 6:\"0R\", 7:\"1R\", 8:\"2R\", 9:\"3R\", 10:\"4R\", 11:\"5R\"}\n",
    "indice_to_label = {6:\"None\", 0:\"0\", 1:\"1\", 2:\"2\", 3:\"3\", 4:\"4\", 5:\"5\"}\n",
    "label_to_indice = {v:k for k,v in indice_to_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "lower_gray = np.array([42], dtype = \"uint8\")\n",
    "upper_gray = np.array([176], dtype = \"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_from_video(img):\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    _,img = cv2.threshold(img,20,255,cv2.THRESH_BINARY)\n",
    "    #kernel = np.ones((3,3),np.uint8)\n",
    "    #img = cv2.dilate(img, kernel, iterations = 1)\n",
    "    #img = cv2.erode(img, kernel, iterations = 1)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "def process_image_for_training(img):\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    _,img = cv2.threshold(img,80,255,cv2.THRESH_BINARY)\n",
    "    img = img/255\n",
    "    return img\n",
    "\n",
    "def img_to_sample(img):\n",
    "    img = img.astype(np.uint8)\n",
    "    img = np.reshape(img, (128, 128))\n",
    "    \n",
    "    img = process_image_for_training(img)\n",
    "    \n",
    "    img = np.reshape(img, (128, 128, 1))\n",
    "    return img\n",
    "\n",
    "def loadModel(architecturePath=\"handmodel_fingers_architecture.json\", weightsPath=\"handmodel_fingers_weights.hdf5\"):\n",
    "    # Model reconstruction from JSON file\n",
    "    with open(architecturePath, 'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "\n",
    "    # Load weights into the new model\n",
    "    model.load_weights(weightsPath)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_iceland.0\"\n"
     ]
    }
   ],
   "source": [
    "model = loadModel(architecturePath=\"handmodel_fingers_architecture.json\", weightsPath=\"handmodel_fingers_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "\n",
    "def frame_to_hand_pose(gray, x1, y1, x2, y2, name):\n",
    "    zone = gray[y1:y2, x1:x2, :]\n",
    "    cv2.rectangle(gray,(x1,y1),(x2,y2),(0,255,0),3)\n",
    "    \n",
    "    zone = cv2.cvtColor(zone, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow('HSV zone {}'.format(name),zone)\n",
    "    \n",
    "    skinMask = cv2.inRange(zone, lower, upper)\n",
    "    skinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.erode(skinMask, kernel, iterations = 2)\n",
    "    skinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)\n",
    "    \n",
    "    zone = cv2.bitwise_and(zone, zone, mask = skinMask)\n",
    "    zone = cv2.cvtColor(zone, cv2.COLOR_BGR2GRAY)\n",
    "    zone = process_image_from_video(zone)\n",
    "    \n",
    "    for_prediction = zone.reshape((1, 128, 128, 1))\n",
    "    \n",
    "    center = zone[64, 64]\n",
    "    predicted_class = 6\n",
    "    labels = \"\"\n",
    "    \n",
    "    if center != 0:\n",
    "        preds = model.predict(for_prediction)\n",
    "        predicted_class = np.argmax(preds)\n",
    "        #labels = [\"{} : {}%\".format(k, format(preds[0][v]*100, '.2f')) for k,v in label_to_indice.items()]\n",
    "    \n",
    "    cv2.imshow('What the Network Sees {}'.format(name), zone)\n",
    "    \n",
    "    return center, predicted_class, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "keyboard = Controller()\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.flip(frame,1)\n",
    "    \n",
    "    center_left, predicted_class_left, labels_left = frame_to_hand_pose(gray, 10, 100, 260, 350, \"left\")\n",
    "    center_right, predicted_class_right, labels_right = frame_to_hand_pose(gray, 400, 100, 650, 350, \"right\")\n",
    "    \n",
    "    if center_left == 1.0:\n",
    "        keyboard.press(Key.left) \n",
    "        None\n",
    "    elif center_right == 1.0:\n",
    "        keyboard.press(Key.right)\n",
    "        None\n",
    "    else:\n",
    "        keyboard.release(Key.right)\n",
    "        keyboard.release(Key.left)\n",
    "        None\n",
    "        \n",
    "    if predicted_class_left == 5 or predicted_class_left == 4 or predicted_class_right == 5 or predicted_class_right == 4:\n",
    "        keyboard.press(Key.space)\n",
    "        #keyboard.release(Key.space)\n",
    "        None\n",
    "    else:\n",
    "        keyboard.release(Key.space)\n",
    "        None\n",
    "    \n",
    "    y = 100\n",
    "    cv2.putText(gray,indice_to_label[int(predicted_class_left)],(270,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,0,0),2,cv2.LINE_AA)\n",
    "    if labels_left != \"\":\n",
    "        for label in labels_left:\n",
    "            y = y + 20\n",
    "            cv2.putText(gray, label,(270, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,0,0),2,cv2.LINE_AA)\n",
    "        \n",
    "    yy = 250\n",
    "    cv2.putText(gray,indice_to_label[int(predicted_class_right)],(270,yy), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,0,0),2,cv2.LINE_AA)\n",
    "    if labels_right != \"\":\n",
    "        for label in labels_right:\n",
    "            yy = yy + 20\n",
    "            cv2.putText(gray, label,(270, yy), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,0,0),2,cv2.LINE_AA)\n",
    "\n",
    "    # Display the resulting frame      \n",
    "    cv2.imshow('frame', gray)\n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break                                                                                                                     \n",
    "                                                                   \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
